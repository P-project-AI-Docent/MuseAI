# nlp/inference_intent.py
# ---------------------------------------
# Intent Prediction (with Keyword Boosting)
# ---------------------------------------

import os
import json
import torch
import re
from transformers import AutoTokenizer
from nlp.train_intent_classifier import IntentClassifier, MODEL_NAME

# ---------------------------
# DEVICE ìë™ ì„ íƒ
# ---------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"[DEVICE] Using {DEVICE}")

# ---------------------------
# ë ˆì´ë¸” ë¡œë“œ
# ---------------------------
LABEL_PATH = "nlp/intent_labels.json"
if not os.path.exists(LABEL_PATH):
    raise FileNotFoundError("intent_labels.json ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

with open(LABEL_PATH, "r", encoding="utf-8") as f:
    labels = json.load(f)

id2label = {int(k): v for k, v in labels.items()}
label2id = {v: k for k, v in id2label.items()}


# ============================================================
# ğŸ” Keyword Boosting Rules (ìµœì‹  ì—…ë°ì´íŠ¸)
# ============================================================
KEYWORDS = {
    # ê¸°ë³¸ ì„¤ëª…
    "artwork_overview": {
        "words": ["ì†Œê°œ", "ê°œìš”", "ìš”ì•½", "ì „ì²´ì ", "ì „ë°˜ì ", "ì„¤ëª…"],
        "boost": 0.9
    },

    # ì‘ê°€ ì •ë³´
    "artist_info": {
        "words": ["ì‘ê°€", "ì˜ˆìˆ ê°€", "ëˆ„êµ¬", "ê·¸ë¦°", "ë§Œë“  ì‚¬ëŒ", "í™”ê°€"],
        "boost": 1.0
    },

    # ì œì‘ ì‹œê¸°
    "date_query": {
        "words": ["ì–¸ì œ", "ë…„ë„", "ì—°ë„", "ì‹œê¸°", "ì‹œëŒ€"],
        "boost": 0.9
    },

    # ì¬ë£Œ
    "medium_query": {
        "words": ["ì¬ë£Œ", "ì†Œì¬", "ì¬ì§ˆ", "ë¬´ì—‡ìœ¼ë¡œ", "ì–´ë–¤ ì¬ë£Œ"],
        "boost": 0.9
    },

    # ë©”íƒ€ë°ì´í„° ì •ë³´
    "metadata_query": {
        "words": ["ì œëª©", "ë²ˆí˜¸", "ì•„ì´ë””", "í¬ê¸°", "ì •ë³´"],
        "boost": 0.7
    },

    # ============================================================
    # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” í•µì‹¬ intent
    # ============================================================

    # 1ë‹¨ê³„: "ìœ ì‚¬í•œ ì‘í’ˆ ì•Œë ¤ì¤˜"
    "similar_artwork": {
        "words": ["ë¹„ìŠ·", "ìœ ì‚¬", "ì¶”ì²œ", "ë‹®ì€", "ê°™ì€ ëŠë‚Œ", "ë¹„ìŠ·í•œ ì‘í’ˆ"],
        "boost": 1.2
    },

    # 2ë‹¨ê³„ ì„ íƒì§€: ì‹œê°ì 
    "related_visual": {
        "words": ["ì‹œê°", "ë¹„ì£¼ì–¼", "ìƒ‰ê°", "ë¹„ìŠ·í•˜ê²Œ ìƒê¸´", "ê²‰ëª¨ìŠµ", "ì™¸í˜•"],
        "boost": 1.3
    },

    # 2ë‹¨ê³„ ì„ íƒì§€: ë¬¸ë§¥/ì£¼ì œ
    "related_context": {
        "words": ["ì£¼ì œ", "ë‚´ìš©", "ë§¥ë½", "ì‚¬ì¡°", "ì„¤ëª… ê¸°ë°˜", "ë¬¸ë§¥"],
        "boost": 1.2
    },

    # ìŠ¤íƒ€ì¼/ê¸°ë²•
    "style_context": {
        "words": ["ìŠ¤íƒ€ì¼", "ì–‘ì‹", "í™”í’", "ì‚¬ì¡°", "ê¸°ë²•", "ë¯¸ìˆ ì‚¬"],
        "boost": 0.7
    },

    # fallback
    "fallback": {"words": [], "boost": 0.0},
}


# ============================================================
# í…ìŠ¤íŠ¸ ì •ê·œí™”
# ============================================================
def normalize_text(text: str) -> str:
    text = text.strip()
    text = re.sub(r"\s+", " ", text)
    return text


# ============================================================
# Keyword Boosting
# ============================================================
def apply_keyword_boost(query: str, logits: torch.Tensor):
    query = normalize_text(query)
    tokens = query.split()

    logits = logits.clone()

    for intent, cfg in KEYWORDS.items():
        intent_id = label2id[intent]
        boost_val = cfg["boost"]

        for kw in cfg["words"]:
            if kw in query or kw in tokens:
                logits[0][intent_id] += boost_val

    return logits


# ============================================================
# ëª¨ë¸ ë¡œë“œ
# ============================================================
tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    use_fast=True,
    local_files_only=True
)

model = IntentClassifier(num_labels=len(id2label))
ckpt_path = "nlp/intent_classifier_best.pt"
if not os.path.exists(ckpt_path):
    ckpt_path = "nlp/intent_classifier.pt"

model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))
model.to(DEVICE)
model.eval()

MAX_LEN = 96


# ============================================================
# ì˜ˆì¸¡ í•¨ìˆ˜
# ============================================================
@torch.no_grad()
def predict_intent(text: str) -> str:
    text = normalize_text(text)

    enc = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=MAX_LEN
    )

    logits = model(
        enc["input_ids"].to(DEVICE),
        enc["attention_mask"].to(DEVICE)
    )

    # Keyword boosting ì ìš©
    logits = apply_keyword_boost(text, logits)

    pred = logits.argmax(dim=1).item()
    return id2label[pred]


# ============================================================
# CLI í…ŒìŠ¤íŠ¸
# ============================================================
if __name__ == "__main__":
    print("ì˜ë„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œ. exit ì…ë ¥ ì‹œ ì¢…ë£Œ.")
    while True:
        q = input("\nì§ˆë¬¸: ").strip()
        if q.lower() == "exit":
            break
        print(" â†’ intent:", predict_intent(q))
